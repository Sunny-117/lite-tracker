# 部署mysql和redis，修改fee，并部署server部分

**环境：**

- win10物理机
- Wmare Centos7虚拟机C

**本次主要内容：**

- 配置和部署mysql、redis
- 配置和部署fee server，对接昨天部署的kafka

## 1. Mysql

我们用Mysql对校验、聚合后的日志数据做持久化存储

### 1.1 安装和配置mysql

- 编辑mysql5.7的yum源`/etc/yum.repos.d/mysql-community.repo`

    ```bash
    # /etc/yum.repos.d/mysql-community.repo
    [mysql-connectors-community]
    name=MySQL Connectors Community
    baseurl=https://mirrors.tuna.tsinghua.edu.cn/mysql/yum/mysql-connectors-community-el7-$basearch/
    enabled=1
    gpgcheck=1
    gpgkey=https://repo.mysql.com/RPM-GPG-KEY-mysql

    [mysql-tools-community]
    name=MySQL Tools Community
    baseurl=https://mirrors.tuna.tsinghua.edu.cn/mysql/yum/mysql-tools-community-el7-$basearch/
    enabled=1
    gpgcheck=1
    gpgkey=https://repo.mysql.com/RPM-GPG-KEY-mysql

    [mysql-5.7-community]
    name=MySQL 5.7 Community Server
    baseurl=https://mirrors.tuna.tsinghua.edu.cn/mysql/yum/mysql-5.7-community-el7-$basearch/
    enabled=1
    gpgcheck=1
    gpgkey=https://repo.mysql.com/RPM-GPG-KEY-mysql
    ```

- 安装mysql

    ```bash
    yum install mysql-community-server -y
    ```

- 启动mysql

    ```bash
    sudo systemctl start mysqld
    sudo systemctl enable mysqld
    sudo systemctl status mysqld
    ```

- 获取root密码

    ```bash
    grep 'temporary password' /var/log/mysqld.log
    ```

- 安装mysql installation tool

    ```bash
    mysql_secure_installation
    ```

    - 依次输入新密码，例如`qweQWE123!@#`
    - `Remove anonymous users?`选`n`
    - `Disallow root login remotely`选`n`
    - `Remove test database and access to it?`选`n`
    - `Reload privilege tables now?`选`n`

- 关闭防火墙

    ```bash
    systemctl disable firewalld.service
    systemctl stop firewalld.service
    setenforce 0
    # 在 /etc/selinux/config 文件中新增一行SELINUX=disabled
    # 注意！不要把SELINUXTYPE=targeted改了
    vim /etc/selinux/config
    ```

- 设置mysql允许root访问

    ```bash
    mysql -u root -p
    # 输入密码 qweQWE123!@#
    # 允许root远程访问
    GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'qweQWE123!@#' WITH GRANT OPTION;
    # 刷新
    FLUSH PRIVILEGES;
    ```

### 1.2 初始化数据库

- 在登陆mysql客户端状态下，创建fee数据库

    ```mysql
    create database fee;
    ```

- 然后cd到`fee`项目中，并编译项目，参见3.1，然后

- 执行`npm run prod_fee Utils:GenerateSQL 1 '2020-09' '2020-11' > init.sql` 生成数据库表初始化文件

    ```js
    `
    Utils:GenerateSQL
    {projectIdList:项目id列表,逗号分割}
    {startAtYm:建表日期开始时间(包括该时间),${DATE_FORMAT.COMMAND_ARGUMENT_BY_MONTH}格式}
    {finishAtYm:建表日期结束时间(包括该时间),${DATE_FORMAT.COMMAND_ARGUMENT_BY_MONTH}格式}
    `
    ```

- 表名说明

    - 所有表都以t_开头
    - 原始表添加_o后缀，即t_o_
    - 结果表添加_r后续，即t_r_
    - 表名、字段名默认使用下划线方式命名，不区分大小写
    - 数据库编码字符集为utf8mb4
    - 记录ID用unsigned bigint
    - 如果字段名有关键字，需要加_c前缀
    - 所有表中必须有update_time 和create_time字段

- 数据库表

    - `t_o_project` 项目名表
    - `t_o_project_member` 项目成员表
    - `t_o_user` 用户表
    - `t_r_behavior_distribution` 主动上报信息表
    - `t_r_duration_distribution` 用户停留时间表
    - `t_r_new_user_summary` 新用户表
    - `t_o_user_first_login_at_1` 首次登陆用户信息表
    - `t_r_city_distribution_1_202009` 城市分布表
    - `t_r_page_view` PV统计表
    - `t_o_uv_record_1_202009` UV记录表
    - `t_r_unique_view` UV统计表
    - `t_r_system_browser` 浏览器信息表
    - `t_r_system_runtime_version` 应用版本信息表
    - `t_r_system_device` 设备信息表
    - `t_r_system_os` 操作系统信息表
    - `t_o_system_collection_1` 系统设备浏览器信息收集表
    - `t_o_alarm_config` 报警配置表
    - `t_r_alarm_log` 报警日志表
    - `t_o_monitor_1_202009` 错误信息表
    - `t_o_monitor_ext_1_202009` 错误扩展信息表
    - `t_r_error_summary_1_202009` 错误汇总表
    - `t_r_performance_1_202009` 性能指标表
    - `t_r_http_error_distribution` http请求错误表

- `vi init.sql`删除最前面两行的注释，然后执行`mysql -u root -h 127.0.0.1 fee -p < init.sql`, 执行建表语句

- 登陆mysql，`mysql -u root -p`，进入fee数据库`use fee`，通过插入语句创建新项目

    ```js
    // id, 抽样比率, 项目名(展示), 项目id, 负责人信息
    // project_test_id
    REPLACE INTO `t_o_project` (`id`, `rate`, `display_name`, `project_name`, `c_desc`, `is_delete`, `create_ucid`, `update_ucid`, `create_time`, `update_time`) VALUES (1, 10000, '测试项目', 'project_test_id', '测试项目负责人', 0, '', '', 0, 0);
    ```

参考链接：

- [MySQL官网](https://www.mysql.com/cn/)
- [MySQL国内源](https://mirrors.tuna.tsinghua.edu.cn/help/mysql/)

## 2. Redis

### 2.1 安装和配置redis

- 安装redis

    ```bash
    yum install -y epel-release
    yum install -y redis
    ```

- 设置redis密码，`vim /etc/redis.conf`，找到`#requirepass foobared`，去掉注释，并把`foobared`修改为你的密码，例如：`qweQWE123!@#`

- 启动redis

    ```bash
    systemctl start redis
    systemctl enable redis
    ```

参考链接:

- [Redis官网](https://redis.io/)

## 3. fee server

我们在虚拟机C，使用`git clone`下载fee仓库，然后进入fee仓库的server目录，可以看到`fee server`部分包括两个部分：

1. `task server`：负责启动定时任务，消费kafka，校验、消费日志，并落库持久化
2. `api server`：负责封装可视化展示用的`rest api`

### 3.1 安装依赖

- 作为kafka消费者，`fee server`依赖`node-rdkafka`作为kafka客户端与kafka连接

- 为确保`node-rdkafka`顺利编译和运行，检查是否安装了`gcc+`、`gcc-c++`、`zlib-devel`，否则可能产生难以定位的问题。

    ```bash
    yum install -y gcc+ gcc-c++ zlib-devel
    ```

- 安装`node_modules`

    ```bash
    npm i --registry=https://registry.npm.taobao.org
    ```

- 或者使用cnpm安装

    ```bash
    npm install -g cnpm --registry=https://registry.npm.taobao.org
    cnpm install
    ```

参考链接:

- [node-rdkafka github地址](https://github.com/Blizzard/node-rdkafka)
- [librdkafka github地址](https://github.com/edenhill/librdkafka)

### 3.2 配置fee server

- 配置kafka和alarm开关，`server/src/configs/common.js`

    ```js
    const production = {
        use: {
            kafka: true, // 是否使用kafka。如果没有kafka，设为false，并且指定下面的nginxLogFilePath
            alarm: true
        }
        // ...
    }
    ```

- 配置kafka连接，`server/src/configs/kafka.js`

    ```js
    const production = {
        'group.id': 'fee',
        'metadata.broker.list': '192.168.199.101:9092',
    }
    ```

- 配置mysql连接，`server/src/configs/mysql.js`

    ```js
    const production = {
        host: '127.0.0.1',
        port: '3306',
        user: 'root',
        password: 'qweQWE123!@#',
        database: 'fee'
    }
    ```

- 配置redis连接，`server/src/configs/redis.js`

    ```js
    const production = {
        host: '127.0.0.1',
        port: '6379',
        db: '4',
        password: 'qweQWE123!@#'
    }
    ```

- 配置redis密码，`server/src/library/redis/index.js`

    ```js
    class RedisClient {
    constructor (isTest = false) {
        this.redisClient = new Redis({
        // ...
        password: redisConfig.password,
    ```

- 配置报警，`server/src/configs/alarm.js`

    ```js
    const production = {
        addr: 'https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=0819f455-9431-4045-a833-6bee08485b95',
        app: '前端监控系统fee',
        WATCH_UCID_LIST_DEFAULT: [
            123456 // ***
        ],
        WATCH_UCID_LIST_BACKEND: [
            123456 // ***
        ]
    }
    ```

- 修改`server/src/app.js`

    ```js
    const app = express()
    // 设置存放模板引擎目录
    app.set('views', path.join(__dirname, '../public'))
    // 设置模板引擎为ejs
    // app.set('view engine', 'ejs')
    app.engine('html', ejs.renderFile)
    app.set('view engine', 'html')
    ```

- 修改`server/bin/run.sh`

    ```shell
    FEE_COMMAND="Task:Manager" # 上线时直接把它改成Task:Manager即可
    ```

- 修改`server/src/commands/save_log/parseKafkaLog.js`，适配filebeat

    ```js
    let content = data.value.toString() // 在本句后追加
    // 适配filebeat
    if (content.includes('@timestamp') && content.includes('@metadata')) {
        const dataObj = JSON.parse(content);
        content = dataObj.message || '';
    }
    ```

### 3.3 编译项目

```bash
npm run build
```

### 3.4 启动server

- 安装PM2

    ```bash
    npm i --registry=https://registry.npm.taobao.org pm2 -g
    ```

- 进程守护启动：

    ```bash
    pm2 start ./pm2_fee_task_manager.json --env production
    pm2 start ./pm2_fee_app.json --env production
    ```

- 设置开机启动

    ```bash
    # 保存现有列表数据
    pm2 save
    # 设置开机启动
    pm2 startup
    ```

- 观察server日志：

    ```bash
    # taskManger命令的日志，可以看到任务运行情况
    tail -f ./log/pm2/command/task-manager-out.log
    # save2Log命令的日志，可以看到是否收到数据
    tail -f log/command/Save2Log-2020-xx-xx.log
    # parseMonitor命令的日志，可以看到数据是否被存入数据库中
    tail -f log/command/ParseMonitor-2020-xx-xx.log
    # 等等
    ```

### 3.5 fee源码介绍

- `task server`使用`pm2`启动，配置为：

    ```js
    {
        "name": "fee-task-manager",
        "script": "./dist/fee.js",
        "cwd": "./",
        "args": ["Task:Manager"],
        "watch": [
            "dist"
        ]
    }
    ```

- 实际是调用了`dist/fee.js`，并传入`Task:Manager`参数

- `dist/fee.js`对应的源码为`src/fee.js`，

    ```js
    import ace from '@adonisjs/ace'
    const registedCommandList = [
        './commands/task/manage', //  任务调度
    ]
    // register commands
    for (let command of registedCommandList) {
    ace.addCommand(require(command)['default'])
    }
    // Boot ace to execute commands
    ace.wireUpWithCommander()
    ace.invoke()
    ```

- `Task:Manager`命令的定义在`src/commands/task/manage.js`，可以看到该文件中定义了各种定时任务

    ```js
    class TaskManager extends Base {
        static get signature () {
            return `
            Task:Manager
            `
        }
        static get description () {
            return '任务调度主进程, 只能启动一次'
        }
        async handle (args, options) {
            this.log('任务主进程启动')
            // 注册定时任务
            this.log('注册每分钟执行一次的任务')
            this.registerTaskRepeatPer1Minute()
            this.log('注册每10分钟执行一次的任务')
            this.registerTaskRepeatPer10Minute()
            this.log('注册每1小时执行一次的任务')
            this.registerTaskRepeatPer1Hour()
            this.log('注册每6小时执行一次的任务')
            this.registerTaskRepeatPer6Hour()
            this.log('全部定时任务注册完毕, 等待执行')
        }
    }
    ```

- 我们以`registerTaskRepeatPer1Minute`每分钟执行一次的任务为例

    ```js
    import schedule from 'node-schedule'

    async registerTaskRepeatPer1Minute () {
        let that = this
        // 每分钟的第0秒启动
        schedule.scheduleJob('0 */1 * * * *', function () {
        that.log('registerTaskRepeatPer1Minute 开始执行')

        let nowByMinute = moment().format(DATE_FORMAT.COMMAND_ARGUMENT_BY_MINUTE)
        let twoMinuteAgoByMinute = moment().subtract(2, DATE_FORMAT.UNIT.MINUTE).format(DATE_FORMAT.COMMAND_ARGUMENT_BY_MINUTE)
        let threeMinuteAgoByMinute = moment().subtract(3, DATE_FORMAT.UNIT.MINUTE).format(DATE_FORMAT.COMMAND_ARGUMENT_BY_MINUTE)
        let fourMinuteAgoByMinute = moment().subtract(4, DATE_FORMAT.UNIT.MINUTE).format(DATE_FORMAT.COMMAND_ARGUMENT_BY_MINUTE)
        let fiveMinuteAgoByMinute = moment().subtract(5, DATE_FORMAT.UNIT.MINUTE).format(DATE_FORMAT.COMMAND_ARGUMENT_BY_MINUTE)
        let tenMinuteAgoByMinute = moment().subtract(10, DATE_FORMAT.UNIT.MINUTE).format(DATE_FORMAT.COMMAND_ARGUMENT_BY_MINUTE)

        that.log(`[按分钟] 每分钟启动一次SaveLog `)
        if (isUsingKafka) {
            that.execCommand('SaveLog:Kafka', [])
        } else {
            that.execCommand('SaveLog:Nginx', [])
        }
        that.log(`[按分钟] 每分钟启动一次WatchDog:Alarm, 监控平台运行情况 `)
        that.execCommand('WatchDog:Alarm', [])

        that.log(`[按分钟] 解析kafka日志, 分析错误详情`)
        that.dispatchParseCommand('Parse:Monitor', twoMinuteAgoByMinute, nowByMinute)

        that.log(`[按分钟] 每分钟运行Summary:Error, 分别统计前2,3,4,5,10分钟内的数据`)
        that.dispatchParseCommand('Summary:Error', twoMinuteAgoByMinute, DATE_FORMAT.UNIT.MINUTE)
        that.dispatchParseCommand('Summary:Error', threeMinuteAgoByMinute, DATE_FORMAT.UNIT.MINUTE)
        that.dispatchParseCommand('Summary:Error', fourMinuteAgoByMinute, DATE_FORMAT.UNIT.MINUTE)
        that.dispatchParseCommand('Summary:Error', fiveMinuteAgoByMinute, DATE_FORMAT.UNIT.MINUTE)
        that.dispatchParseCommand('Summary:Error', tenMinuteAgoByMinute, DATE_FORMAT.UNIT.MINUTE)

        that.log('registerTaskRepeatPer1Minute 命令分配完毕')
        })
    }
    ```

- 可以看到其中执行了`SaveLog:Kafka`命令，对应的命令定义文件在`src/commands/save_log/parseKafkaLog.js`

    ```js
    import LKafka from '~/src/library/kafka'

    class Save2Log extends SaveLogBase {
        static get signature () {
            return `
            SaveLog:Kafka
            `
        }

        static get description () {
            return '解析kafka日志, 按日志创建时间将原日志和解析后合法的json日志落在log文件中, 每运行30s自动退出'
        }

        async execute (args, options) {
            // 获取项目列表
            let projectMap = await this.getProjectMap()

            let client = this.getClient()
            this.log('client 获取成功')
            let that = this
            let logCounter = 0
            let legalLogCounter = 0
            let pid = process.pid

            this.log(`[pid:${pid}]本次任务启动于${moment().format(DATE_FORMAT.DISPLAY_BY_SECOND)}, 预计在${MAX_RUN_TIME / 1000}秒后, ${moment().add(MAX_RUN_TIME / 1000, 'seconds').format(DATE_FORMAT.DISPLAY_BY_SECOND)}自动结束`)
            // 开始运行指定时间后, 自动退出
            setTimeout(async () => {
            that.log(`[pid:${pid}]time to disconnect from kafka`)
            client.disconnect(async (err, data) => {
                // 断开链接异常, 强制退出
                that.log(`[pid:${pid}]断开链接失败, error =>`, err, 'data =>', data)
                that.log(`[pid:${pid}]启动强制退出流程`)
                await this.forceExit()
            })
            }, MAX_RUN_TIME)

            // 达到运行指定时间两倍后, 不再等待, 强制退出
            setTimeout(async () => {
            that.log(`[pid:${pid}]运行时间超出限制, 强制退出`)
            await this.forceExit()
            }, MAX_RUN_TIME * 1.5)

            client.on('ready', () => {
            client.subscribe(['fee']) // kafka topic
            client.consume()
            this.log(`[pid:${pid}]kafka 链接成功, 开始录入数据`)
            }).on('data', async (data) => {
            logCounter = logCounter + 1
            let content = data.value.toString()

            // 适配filebeat
            if (content.includes('@timestamp') && content.includes('@metadata')) {
                const dataObj = JSON.parse(content);
                content = dataObj.message || '';
            }

            // 获取日志时间, 没有原始日志时间则直接跳过
            let logCreateAt = this.parseLogCreateAt(content)
            if (_.isFinite(logCreateAt) === false || logCreateAt <= 0) {
                this.log('日志时间不合法, 自动跳过')
                return
            }
            // 首先判断是不是测试数据, 如果是测试数据, 直接保存, 跳过后续所有逻辑
            if (this.isTestLog(content)) {
                this.log('收到测试日志, 直接保存, 并跳过后续所有流程')
                let writeLogClient = this.getWriteStreamClientByType(logCreateAt, LKafka.LOG_TYPE_TEST)
                writeLogClient.write(content)
                this.log('测试日志写入完毕')
                return
            }
            // 检查日志格式, 只录入解析后, 符合规则的log
            let parseResult = await that.parseLog(content, projectMap)
            if (_.isEmpty(parseResult)) {
                that.log('日志格式不规范, 自动跳过, 原日志内容为 =>', content)
                return
            }

            let projectName = _.get(parseResult, ['project_name'], 0)
            let projectRate = _.get(projectMap, [projectName, 'rate'], 100)
            let checkFlag = _.floor(logCounter % 10000)
            let skipIt = checkFlag > projectRate
            if (skipIt) {
                // 根据项目抽样比率，过滤打点数据，如果没有命中，直接返回
                this.log(` projectName => ${projectName}, logCounter => ${logCounter}, checkFlag => ${checkFlag}, projectRate => ${projectRate}, 未命中抽样比, 自动跳过`)
                return
            }
            legalLogCounter = legalLogCounter + 1

            // 存原始数据
            let rawLogWriteStreamByLogCreateAt = this.getWriteStreamClientByType(logCreateAt, LKafka.LOG_TYPE_RAW)
            rawLogWriteStreamByLogCreateAt.write(content)

            this.log(`收到数据, 当前共记录${legalLogCounter}/${logCounter}条数据`)
            let jsonWriteStreamByLogCreateAt = this.getWriteStreamClientByType(logCreateAt, LKafka.LOG_TYPE_JSON)
            jsonWriteStreamByLogCreateAt.write(JSON.stringify(parseResult))
            // 定期清一下
            if (jsonWriteStreamPool.size > 100 || rawLogWriteStreamPool.size > 100) {
                // 每当句柄池满100后, 关闭除距离当前时间10分钟之内的所有文件流
                this.autoCloseOldStream()
            }
            }).on('disconnected', async () => {
            this.log(`[pid:${pid}]链接断开`)
            await this.forceExit()
            })
        }
        getClient () {
            let kafka = LKafka.Kafka
            let client = new kafka.KafkaConsumer(BaseClientConfig, {})
            return client.connect()
        }
    }
    ```

    ```js
    // src/library/kafka/index.js
    import Kafka from 'node-rdkafka'
    export default {
        Kafka
    }
    ```

- 可以看到，`SaveLog:Kafka`命令利用了`node-rdkafka`作为`KafkaConsumer`客户端连接`kafka`

    ```js
    client.on('ready', () => {
        client.subscribe(['fee']) // 订阅topic为fee
        client.consume() // 消费
    }).on('data', async (data) => {
        let content = data.value.toString() // 获取kafka消息内容
        // ...
        // 存原始数据
        let rawLogWriteStreamByLogCreateAt = this.getWriteStreamClientByType(logCreateAt, LKafka.LOG_TYPE_RAW)
        rawLogWriteStreamByLogCreateAt.write(content)
    })
    ```

- 可以看到，`SaveLog:Kafka`命令利用了`getWriteStreamClientByType`方法中的`write`写入文件到本地，这个方法实际来自于`writeLine`模块。这个文件定义在`server/src/commands/save_log/base.js`

    ```js
    import { writeLine } from 'lei-stream'
    function getWriteStreamClientByType (nowAt, logType = LKafka.LOG_TYPE_RAW) {
        nowAtWriteStream = writeLine(
            fs.createWriteStream(nowAtLogUri, { flags: 'a' }),
            {
                newline: '\n', // 换行符，默认\n
                encoding: null,
                cacheLines: 0 // 直接落磁盘
            }
        )
    }
    ```

- 当我们成功运行该命令后，会发现kafka消息被按照日期写入在了`server/log/kafka/raw/month_202009/day_xx/xx/xx.log`相关目录和文件中

- 至此，在1分钟的定时任务中，我们了解到了`SaveLog:Kafka`命令做了两件事：消费kafka消息，并写入到本地文件中。下面我们继续看1分钟的定时任务中的其他命令，可以看到`Parse:Monitor`命令

    ```js
    // server/src/commands/task/manage.js
    that.log(`[按分钟] 解析kafka日志, 分析错误详情`)
    that.dispatchParseCommand('Parse:Monitor', twoMinuteAgoByMinute, nowByMinute)
    ```

- `Parse:Monitor`命令被定义在了`server/src/commands/parse/monitor.js`中

    ```js
    class ParseMonitor extends ParseBase {
    static get signature() {
        return `
        Parse:Monitor
        {startAtYmdHi:日志扫描范围上限${DATE_FORMAT.COMMAND_ARGUMENT_BY_MINUTE}格式}
        {endAtYmdHi:日志扫描范围下限${DATE_FORMAT.COMMAND_ARGUMENT_BY_MINUTE}格式}
        `
    }

    static get description() {
        return '[按分钟] 解析kafka日志, 分析Monitor'
    }
    /**
     * 解析消息内容，选取和monitor相关的数据并格式化后，
     * 把相关内容存入this.projectMap中
     */
    async processRecordAndCacheInProjectMap(record) {
        let visitAtMap = new Map()
        this.projectMap.set(projectId, visitAtMap)
    }
    /*
     * 把projectMap信息入库
     */
    async save2DB() {
        for (let [projectId, visitAtMap] of this.projectMap) {
            for (let [visitAtTime, monitorMap] of visitAtMap) {
                // monitor查询参数
                let monitorParams = {
                    projectId: projectId,
                    tableName: BaseTableName,
                    splitBy: MCommon.SPLIT_BY.MONTH,
                    select: 'monitor_ext_id',
                    where: {
                    log_at: visitAt,
                    md5: monitorRecord.md5
                    }
                }
                // monitor_ext查询更新参数
                let monitorExtParams = {
                    projectId: projectId,
                    tableName: 't_o_monitor_ext',
                    datas: {
                    ext_json: JSON.stringify(extraData)
                    },
                    splitBy: MCommon.SPLIT_BY.MONTH
                }
                // 入库
                let monitorRes = await MCommon.insertInto(monitorExtParams)
                sqlRecord.monitor_ext_id = monitorRes[0]
                monitorParams.datas = sqlRecord
                let isSuccess = await MCommon.replaceInto(monitorParams)
            }
        }
    }
    ```

- 可以看到`Parse:Monitor`命令解析了消息内容，并入库。其中`insertInto`和`replaceInto`是对SQL客户端`knex`的封装

    ```js
    // src/model/parse/common.js
    import Knex from '~/src/library/mysql'

    async function insertInto (infos) {
        const { projectId, tableName, splitBy, datas } = infos
        let updateAt = moment().unix()
        if (!datas['create_time']) {
            datas['create_time'] = updateAt
        }
        if (!datas['update_time']) {
            datas['update_time'] = updateAt
        }
        const TableName = getTableName(tableName, splitBy, projectId)
        return Knex(TableName)
            .insert(datas)
            .catch(() => { return 0 })
    }
    ```

    ```js
    // src/library/mysql/index.js
    import knex from 'knex'
    const Knex = knex({
        client: 'mysql',
        connection: {
            host: sqlconfig.host,
            port: sqlconfig.port,
            database: sqlconfig.database,
            user: sqlconfig.user,
            password: sqlconfig.password
        },
        // ...
    }
    export default Knex
    ```

- 还有更多的任务和命令，不做一一介绍，我们可以继续进一步自行研究

    - 每分钟任务

        - `SaveLog:Kafka` 读取kafka日志消息，并保存到本地
        - `WatchDog:Alarm` 监控平台运行情况
        - `Parse:Monitor` 解析kafka日志, 分析错误详情
        - `Summary:Error` 分别统计前2,3,4,5,10分钟内的数据

    - 每10分钟任务

        - `CreateCache:UpdatePerOneMinute` 主动调用方法, 更新Redis缓存
        - `Parse:UV` 解析近15分钟数据，分析记录指定时间范围内的uv
        - `Parse:TimeOnSiteByHour` 解析近15分钟数据，分析记录指定时间范围内用户停留时长
        - `Parse:Performance` 解析近15分钟数据，分析分钟级别的指定时间范围内的性能指标
        - `Parse:Monitor` 解析近15分钟数据，分析分钟级别的指定时间范围内的错误详情
        - `Summary:UV` 汇总当前和上个小时的数据，[按小时/按天/按月] 根据历史数据, 汇总分析记录指定时间范围内的uv
        - `Summary:NewUser` 汇总当前和上个小时的数据，[按小时/按天/按月] 根据历史数据, 汇总分析记录指定时间范围内的新增用户数
        - `Summary:Performance` 汇总当前和上个小时的数据，[按小时/按天/按月] 根据历史数据, 汇总分析记录指定时间范围内的性能指标数据
        - `Summary:Error` 汇总当前和上个小时的数据，[按分钟/按小时/按天] 根据历史数据, 汇总分析错误数

    - 每小时任务

        - `Parse:Device` 解析昨日数据，分析指定时间范围Device
        - `Parse:MenuClick` 解析昨日数据，用户点击情况
        - `Parse:UserFirstLoginAt` 解析昨日数据，记录用户首次登陆时间
        - `Summary:UV` 汇总当日数据，[按小时/按天/按月] 根据历史数据, 汇总分析记录指定时间范围内的uv
        - `Summary:NewUser` 汇总当日数据，[按小时/按天/按月] 根据历史数据, 汇总分析记录指定时间范围内的新增用户数
        - `Summary:Performance` 汇总当日数据，[按小时/按天/按月] 根据历史数据, 汇总分析记录指定时间范围内的性能指标数据
        - `Summary:Error` 汇总当日数据，[按分钟/按小时/按天] 根据历史数据, 汇总分析错误数
        - `Summary:TimeOnSite` 汇总当日数据，[按天/按月] 根据历史数据, 汇总分析记录指定时间范围内用户停留时长

    - 每6小时任务

        - `Summary:UV` 汇总昨日数据
        - `Summary:NewUser` 汇总昨日数据
        - `Summary:Performance` 汇总昨日数据
        - `Summary:Error` 汇总昨日数据
        - `Summary:TimeOnSite` 汇总昨日数据
        - `Summary:UV` 汇总当月和上月数据
        - `Summary:NewUser` 汇总当月和上月数据
        - `Summary:Performance` 汇总当月和上月数据
        - `Summary:TimeOnSite` 汇总当月和上月数据，[按天/按月] 根据历史数据, 汇总分析记录指定时间范围内用户停留时长
        - `Summary:SystemBrowser` 汇当月和总上月数据，[按月] 基于数据库统计浏览器占比
        - `Summary:SystemDevice` 汇当月和总上月数据，[按月] 基于数据库统计设备占比
        - `Summary:SystemOS` 汇总当月和上月数据，[按月]基于数据库统计操作系统占比
        - `Utils:CleanOldLog` 清理历史log

### 3.6 附：调试相关

- 启动server watch，响应实时修改

    ```bash
    npm run watch
    ```

- 开发启动

    ```bash
    npm run dev
    ```

- 前台启动

    ```bash
    ./bin sh ./run.sh run production
    ```

- kafka消费调试

    ```bash
    env NODE_ENV=production node dist/fee.js SaveLog:Kafka
    ```

- 入库调试

    ```bash
    # [按小时] 解析nginx日志, 分析分钟级别的指定时间范围内的性能指标
    NODE_ENV=testing node dist/fee.js Parse:Monitor "2020-09-01 10:26"  "2020-09-01 14:27"
    ```

- 汇总调试

    ```bash
    NODE_ENV=testing node dist/fee.js Summary:Performance "2020-09-01 14" hour
    NODE_ENV=testing node dist/fee.js Summary:Performance "2020-09-01" day
    NODE_ENV=testing node dist/fee.js Summary:Performance "2020-09" month
    ```
